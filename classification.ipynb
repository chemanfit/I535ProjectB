{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_uri=\"mongodb://10.75.13.8/fires.fires\"\n",
    "output_uri=\"mongodb://10.75.13.8/fires.fires\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- COMPLEX_NAME: string (nullable = true)\n",
      " |-- CONT_DATE: timestamp (nullable = true)\n",
      " |-- CONT_DOY: double (nullable = true)\n",
      " |-- CONT_TIME: string (nullable = true)\n",
      " |-- COUNTY: string (nullable = true)\n",
      " |-- DISCOVERY_DATE: timestamp (nullable = true)\n",
      " |-- DISCOVERY_DOY: integer (nullable = true)\n",
      " |-- DISCOVERY_TIME: string (nullable = true)\n",
      " |-- FIPS_CODE: string (nullable = true)\n",
      " |-- FIPS_NAME: string (nullable = true)\n",
      " |-- FIRE_CODE: string (nullable = true)\n",
      " |-- FIRE_NAME: string (nullable = true)\n",
      " |-- FIRE_SIZE: double (nullable = true)\n",
      " |-- FIRE_SIZE_CLASS: string (nullable = true)\n",
      " |-- FIRE_YEAR: integer (nullable = true)\n",
      " |-- FOD_ID: integer (nullable = true)\n",
      " |-- FPA_ID: string (nullable = true)\n",
      " |-- ICS_209_INCIDENT_NUMBER: string (nullable = true)\n",
      " |-- ICS_209_NAME: string (nullable = true)\n",
      " |-- LATITUDE: double (nullable = true)\n",
      " |-- LOCAL_FIRE_REPORT_ID: string (nullable = true)\n",
      " |-- LOCAL_INCIDENT_ID: string (nullable = true)\n",
      " |-- LONGITUDE: double (nullable = true)\n",
      " |-- MTBS_FIRE_NAME: string (nullable = true)\n",
      " |-- MTBS_ID: string (nullable = true)\n",
      " |-- NWCG_REPORTING_AGENCY: string (nullable = true)\n",
      " |-- NWCG_REPORTING_UNIT_ID: string (nullable = true)\n",
      " |-- NWCG_REPORTING_UNIT_NAME: string (nullable = true)\n",
      " |-- OBJECTID: integer (nullable = true)\n",
      " |-- OWNER_CODE: double (nullable = true)\n",
      " |-- OWNER_DESCR: string (nullable = true)\n",
      " |-- SOURCE_REPORTING_UNIT: string (nullable = true)\n",
      " |-- SOURCE_REPORTING_UNIT_NAME: string (nullable = true)\n",
      " |-- SOURCE_SYSTEM: string (nullable = true)\n",
      " |-- SOURCE_SYSTEM_TYPE: string (nullable = true)\n",
      " |-- STATE: string (nullable = true)\n",
      " |-- STAT_CAUSE_CODE: double (nullable = true)\n",
      " |-- STAT_CAUSE_DESCR: string (nullable = true)\n",
      " |-- Shape: binary (nullable = true)\n",
      " |-- _id: struct (nullable = true)\n",
      " |    |-- oid: string (nullable = true)\n",
      " |-- index: integer (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "myspark=SparkSession.builder.appName(\"wildfire\").config(\"spark.mongodb.input.uri\", input_uri).config(\"spark.mongodb.output.uri\", output_uri).config('spark.jars.packages', 'org.mongodb.spark:mongo-spark-connector_2.12:3.0.0').getOrCreate()\n",
    "\n",
    "df=myspark.read.format('com.mongodb.spark.sql.DefaultSource').load()\n",
    "\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView(\"wildfires\")\n",
    "\n",
    "#select our features and target for the classification\n",
    "SQL_QUERY =\"SELECT STATE, \\\n",
    "            month(DISCOVERY_DATE) as month, \\\n",
    "            dayofweek(DISCOVERY_DATE) as day, \\\n",
    "            LATITUDE, \\\n",
    "            LONGITUDE, \\\n",
    "            FIRE_SIZE, \\\n",
    "            ABS(datediff(CONT_DATE,DISCOVERY_DATE)) as burn_dur, \\\n",
    "            STAT_CAUSE_DESCR as cause \\\n",
    "            from wildfires\"\n",
    "class_df=myspark.sql(SQL_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+-----------+-------------+---------+--------+--------------+\n",
      "|STATE|month|day|   LATITUDE|    LONGITUDE|FIRE_SIZE|burn_dur|         cause|\n",
      "+-----+-----+---+-----------+-------------+---------+--------+--------------+\n",
      "|   CA|    2|  4|40.03694444|-121.00583333|      0.1|       0| Miscellaneous|\n",
      "|   CA|    5|  4|38.93305556|-120.40444444|     0.25|       0|     Lightning|\n",
      "|   CA|    5|  2|38.98416667|-120.73555556|      0.1|       0|Debris Burning|\n",
      "|   CA|    6|  2|38.55916667|-119.91333333|      0.1|       5|     Lightning|\n",
      "|   CA|    6|  2|38.55916667|-119.93305556|      0.1|       5|     Lightning|\n",
      "|   CA|    6|  4|38.63527778|-120.10361111|      0.1|       1|     Lightning|\n",
      "|   CA|    7|  5|38.68833333|-120.15333333|      0.1|       1|     Lightning|\n",
      "|   CA|    3|  3|40.96805556|-122.43388889|      0.8|       0|Debris Burning|\n",
      "|   CA|    3|  3|41.23361111|-122.28333333|      1.0|       0|Debris Burning|\n",
      "|   CA|    7|  5|38.54833333|-120.14916667|      0.1|       1|     Lightning|\n",
      "|   CA|    7|  6|38.69166667|-120.15972222|      0.1|       1|     Lightning|\n",
      "|   CA|    7|  6|    38.5275|-120.10611111|      0.1|       1|     Lightning|\n",
      "|   CA|    9|  6|38.78666667|-120.19333333|      0.1|       0| Miscellaneous|\n",
      "|   CA|    9|  3|38.43333333|      -120.51|      6.0|       0|      Campfire|\n",
      "|   CA|   10|  1|38.67583333|-120.27972222|      0.2|       0|     Lightning|\n",
      "|   CA|   10|  1|38.56416667|-120.54222222|      0.1|       0|     Lightning|\n",
      "|   CA|   10|  4|38.52333333|-120.21166667|  16823.0|      15| Equipment Use|\n",
      "|   CA|   10|  4|      38.78|      -120.26|   7700.0|       4| Equipment Use|\n",
      "|   CA|   11|  7|     38.945|-120.41166667|      0.1|       1|Debris Burning|\n",
      "|   NM|    6|  6|33.44083333|-105.72055556|      0.1|       0|     Lightning|\n",
      "+-----+-----+---+-----------+-------------+---------+--------+--------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(class_df.show())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('STATE', 'string'),\n",
       " ('month', 'int'),\n",
       " ('day', 'int'),\n",
       " ('LATITUDE', 'double'),\n",
       " ('LONGITUDE', 'double'),\n",
       " ('FIRE_SIZE', 'double'),\n",
       " ('burn_dur', 'int'),\n",
       " ('cause', 'string')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#since we have categorical and string data we need to put these into numeric values\n",
    "#for the machine learning to work\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets make a list of the columns that need to be onehotencoded and those that are numerical\n",
    "catCols=['STATE', 'cause']\n",
    "numCols=['month', 'day', 'LATITUDE', 'LONGITUDE', 'FIRE_SIZE', 'burn_dur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = class_df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_89092406c63a, StringIndexer_c19c9120a3dd]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prior to onehotencoding we first stringindex\n",
    "#we will index the cause for the label use only\n",
    "string_indexer=[\n",
    "    StringIndexer(inputCol=x, outputCol=x+\"_StringIndexer\", handleInvalid=\"skip\")\n",
    "    for x in catCols\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[OneHotEncoder_1a5fc8e9635f]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we don't want to one_hot_encode the cause since it is the target\n",
    "one_hot_encoder=[\n",
    "    OneHotEncoder(\n",
    "        inputCols=[\"STATE_StringIndexer\"],\n",
    "        outputCols=[\"STATE_OneHotEncoder\"]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we assemble the features into a feature vector\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['month',\n",
       " 'day',\n",
       " 'LATITUDE',\n",
       " 'LONGITUDE',\n",
       " 'FIRE_SIZE',\n",
       " 'burn_dur',\n",
       " 'STATE_OneHotEncoder']"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assemblerInput= [x for x in numCols]\n",
    "assemblerInput += [\"STATE_OneHotEncoder\"]\n",
    "#check the columns are as we expect\n",
    "assemblerInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler=VectorAssembler(\n",
    "    inputCols=assemblerInput,\n",
    "    outputCol=\"features\",\n",
    "    handleInvalid=\"skip\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[StringIndexer_89092406c63a,\n",
       " StringIndexer_c19c9120a3dd,\n",
       " OneHotEncoder_1a5fc8e9635f,\n",
       " VectorAssembler_c33b90cff163]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cosntruct our stages for the ML pipeline\n",
    "stages=[]\n",
    "stages+=string_indexer\n",
    "stages+=one_hot_encoder\n",
    "stages+=[vector_assembler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 27.5 ms, sys: 4.04 ms, total: 31.6 ms\n",
      "Wall time: 55.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#now to get our data into shape with the pipeline on the train set and then transform the test set\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "pipeline=Pipeline().setStages(stages)\n",
    "model=pipeline.fit(train)\n",
    "\n",
    "pp_df=model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+---+-----------+-------------+---------+--------+--------------+-------------------+-------------------+-------------------+---------------------------------------------------------------+\n",
      "|STATE|month|day|LATITUDE   |LONGITUDE    |FIRE_SIZE|burn_dur|cause         |STATE_StringIndexer|cause_StringIndexer|STATE_OneHotEncoder|features                                                       |\n",
      "+-----+-----+---+-----------+-------------+---------+--------+--------------+-------------------+-------------------+-------------------+---------------------------------------------------------------+\n",
      "|AK   |3    |1  |58.36111111|-134.62666667|1.0      |0       |Debris Burning|34.0               |0.0                |(51,[34],[1.0])    |(57,[0,1,2,3,4,40],[3.0,1.0,58.36111111,-134.62666667,1.0,1.0])|\n",
      "|AK   |3    |3  |57.78333333|-134.66666667|0.1      |0       |Smoking       |34.0               |8.0                |(51,[34],[1.0])    |(57,[0,1,2,3,4,40],[3.0,3.0,57.78333333,-134.66666667,0.1,1.0])|\n",
      "+-----+-----+---+-----------+-------------+---------+--------+--------------+-------------------+-------------------+-------------------+---------------------------------------------------------------+\n",
      "only showing top 2 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(pp_df.show(2, truncate=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's try Logistic Regression\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pp_df.select(\n",
    "    col(\"features\"),\n",
    "    col(\"cause_StringIndexer\").alias(\"label\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------+-----+\n",
      "|features                                                              |label|\n",
      "+----------------------------------------------------------------------+-----+\n",
      "|(69,[0,1,2,3,4,40,57],[3.0,1.0,58.36111111,-134.62666667,1.0,1.0,1.0])|0.0  |\n",
      "|(69,[0,1,2,3,4,40,65],[3.0,3.0,57.78333333,-134.66666667,0.1,1.0,1.0])|8.0  |\n",
      "|(69,[0,1,2,3,4,5,40,63],[3.0,7.0,57.6,-135.21666667,0.1,1.0,1.0,1.0]) |6.0  |\n",
      "|(69,[0,1,2,3,4,40,58],[4.0,6.0,56.34916667,-132.34,0.1,1.0,1.0])      |1.0  |\n",
      "|(69,[0,1,2,3,4,40,64],[4.0,7.0,55.58333333,-133.03333333,1.0,1.0,1.0])|7.0  |\n",
      "+----------------------------------------------------------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16.1 ms, sys: 326 µs, total: 16.4 ms\n",
      "Wall time: 1min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "log_reg_model=LogisticRegression().fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainingSummary=log_reg_model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "objectiveHistory:\n",
      "2.0868170035109475\n",
      "2.0641286495122633\n",
      "2.017050019070519\n",
      "1.745099953312953\n",
      "1.72858638481694\n",
      "1.721803155785034\n",
      "1.7174234908918775\n",
      "1.7100004654866767\n",
      "1.6991111636980631\n",
      "1.686693617109632\n",
      "1.677581662111939\n",
      "1.6736747810226438\n",
      "1.6720750796939594\n",
      "1.6701783070401255\n",
      "1.6650089060748188\n",
      "1.6632844056686957\n",
      "1.6604309558106642\n",
      "1.6583851472776545\n",
      "1.657429344247666\n",
      "1.6557352471758444\n",
      "1.653923013682503\n",
      "1.6526267246962956\n",
      "1.651774702614614\n",
      "1.650850979253984\n",
      "1.6497779989859869\n",
      "1.6476664919281705\n",
      "1.64663446922236\n",
      "1.6457675043381876\n",
      "1.6451220396546826\n",
      "1.6442756964980376\n",
      "1.643278924416367\n",
      "1.6429379063200038\n",
      "1.6423647224951647\n",
      "1.6421374858532245\n",
      "1.6417021314958302\n",
      "1.6414096840842385\n",
      "1.6410137554780369\n",
      "1.6405827870517629\n",
      "1.6403603121120454\n",
      "1.6398152050234067\n",
      "1.639575440012165\n",
      "1.6393281210129893\n",
      "1.6391939426790694\n",
      "1.6389412383799755\n",
      "1.638607364205586\n",
      "1.6382259845073843\n",
      "1.6377641551054125\n",
      "1.6374197283868301\n",
      "1.637111930626467\n",
      "1.6369239773187836\n",
      "1.6367222187660844\n",
      "1.6363648130219532\n",
      "1.6361112600966394\n",
      "1.6358302696751932\n",
      "1.6357253609209315\n",
      "1.6356046737052012\n",
      "1.635457295897358\n",
      "1.6351710763507097\n",
      "1.6349994827927046\n",
      "1.634777043809857\n",
      "1.634567694645905\n",
      "1.6344295630954948\n",
      "1.634302482171454\n",
      "1.6341193429848704\n",
      "1.6340143421513393\n",
      "1.6338502627154223\n",
      "1.6336747976326935\n",
      "1.6335622994880186\n",
      "1.633433636413165\n",
      "1.6332724971227335\n",
      "1.6331751837151771\n",
      "1.6329921455008258\n",
      "1.6329390584954127\n",
      "1.6328665386886774\n",
      "1.632737951937762\n",
      "1.6326272359223968\n",
      "1.6325054463372384\n",
      "1.6324209556861713\n",
      "1.6323452176715603\n",
      "1.632260980205349\n",
      "1.632183693019964\n",
      "1.6321157165940599\n",
      "1.6320759377237828\n",
      "1.6320096668948831\n",
      "1.6317982598488003\n",
      "1.6317584612333673\n",
      "1.631715049626732\n",
      "1.631659575927414\n",
      "1.6315820282724602\n",
      "1.6315349918789268\n",
      "1.6314960375558782\n",
      "1.6314684093450638\n",
      "1.63143086117514\n",
      "1.6313821717414005\n",
      "1.6313444798668821\n",
      "1.6312935149173315\n",
      "1.6312760742924073\n",
      "1.631249540132018\n",
      "1.6312169658211821\n",
      "1.6311740721089543\n",
      "1.6311402228120804\n"
     ]
    }
   ],
   "source": [
    "objectiveHistory=trainingSummary.objectiveHistory\n",
    "print(\"objectiveHistory:\")\n",
    "for objective in objectiveHistory:\n",
    "    print(objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False positive rate by label:\n",
      "label 0: 0.16833548664944015\n",
      "label 1: 0.08435414719061281\n",
      "label 2: 0.09473912700292052\n",
      "label 3: 0.27259818506721895\n",
      "label 4: 0.02189034518274594\n",
      "label 5: 0.0012384870528278787\n",
      "label 6: 0.0002600919228987779\n",
      "label 7: 0.013100300583159032\n",
      "label 8: 0.0\n",
      "label 9: 0.0\n",
      "label 10: 0.0\n",
      "label 11: 0.0\n",
      "label 12: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"False positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.falsePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True positive rate by label:\n",
      "label 0: 0.5566193049640313\n",
      "label 1: 0.39295150603634\n",
      "label 2: 0.39752216412821095\n",
      "label 3: 0.8856930107605379\n",
      "label 4: 0.4423076923076923\n",
      "label 5: 0.007264070321084117\n",
      "label 6: 0.001976047904191617\n",
      "label 7: 0.09769713886950454\n",
      "label 8: 0.0\n",
      "label 9: 0.0\n",
      "label 10: 0.0\n",
      "label 11: 0.0\n",
      "label 12: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"True positive rate by label:\")\n",
    "for i, rate in enumerate(trainingSummary.truePositiveRateByLabel):\n",
    "    print(\"label %d: %s\" % (i, rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision by label:\n",
      "label 0: 0.43348291432075364\n",
      "label 1: 0.480133108175226\n",
      "label 2: 0.42145473826279767\n",
      "label 3: 0.4929705657678743\n",
      "label 4: 0.6131761086900794\n",
      "label 5: 0.25481798715203424\n",
      "label 6: 0.3113207547169811\n",
      "label 7: 0.18170019467878\n",
      "label 8: 0.0\n",
      "label 9: 0.0\n",
      "label 10: 0.0\n",
      "label 11: 0.0\n",
      "label 12: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision by label:\")\n",
    "for i, prec in enumerate(trainingSummary.precisionByLabel):\n",
    "    print(\"label %d: %s\" % (i, prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall by label:\n",
      "label 0: 0.5566193049640313\n",
      "label 1: 0.39295150603634\n",
      "label 2: 0.39752216412821095\n",
      "label 3: 0.8856930107605379\n",
      "label 4: 0.4423076923076923\n",
      "label 5: 0.007264070321084117\n",
      "label 6: 0.001976047904191617\n",
      "label 7: 0.09769713886950454\n",
      "label 8: 0.0\n",
      "label 9: 0.0\n",
      "label 10: 0.0\n",
      "label 11: 0.0\n",
      "label 12: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall by label:\")\n",
    "for i, rec in enumerate(trainingSummary.recallByLabel):\n",
    "    print(\"label %d: %s\" % (i, rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-measure by label:\n",
      "label 0: 0.48739403625879435\n",
      "label 1: 0.43218956074661896\n",
      "label 2: 0.4091387660560118\n",
      "label 3: 0.6333968519146937\n",
      "label 4: 0.513911268664733\n",
      "label 5: 0.014125467386788534\n",
      "label 6: 0.003927168868261336\n",
      "label 7: 0.12707056954844567\n",
      "label 8: 0.0\n",
      "label 9: 0.0\n",
      "label 10: 0.0\n",
      "label 11: 0.0\n",
      "label 12: 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"F-measure by label:\")\n",
    "for i, f in enumerate(trainingSummary.fMeasureByLabel()):\n",
    "    print(\"label %d: %s\" % (i, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.46792884285570163\n",
      "FPR: 0.12444501350752565\n",
      "TPR: 0.4679288428557017\n",
      "F-measure: 0.4115667715402553\n",
      "Precision: 0.41816999391003773\n",
      "Recall: 0.4679288428557017\n"
     ]
    }
   ],
   "source": [
    "accuracy = trainingSummary.accuracy\n",
    "falsePositiveRate = trainingSummary.weightedFalsePositiveRate\n",
    "truePositiveRate = trainingSummary.weightedTruePositiveRate\n",
    "fMeasure = trainingSummary.weightedFMeasure()\n",
    "precision = trainingSummary.weightedPrecision\n",
    "recall = trainingSummary.weightedRecall\n",
    "print(\"Accuracy: %s\\nFPR: %s\\nTPR: %s\\nF-measure: %s\\nPrecision: %s\\nRecall: %s\"\n",
    "      % (accuracy, falsePositiveRate, truePositiveRate, fMeasure, precision, recall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|cause_StringIndexer|            cause|\n",
      "+-------------------+-----------------+\n",
      "|                0.0|   Debris Burning|\n",
      "|                1.0|    Miscellaneous|\n",
      "|                2.0|            Arson|\n",
      "|                3.0|        Lightning|\n",
      "|                4.0|Missing/Undefined|\n",
      "|                5.0|    Equipment Use|\n",
      "|                6.0|         Campfire|\n",
      "|                7.0|         Children|\n",
      "|                8.0|          Smoking|\n",
      "|                9.0|         Railroad|\n",
      "|               10.0|        Powerline|\n",
      "|               11.0|        Fireworks|\n",
      "|               12.0|        Structure|\n",
      "+-------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp_df.select(\"cause_StringIndexer\", \"cause\").distinct().orderBy(\"cause_StringIndexer\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
